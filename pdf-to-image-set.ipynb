{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "from pytesseract import pytesseract\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_artefacts = True\n",
    "\n",
    "padding_out = 60\n",
    "img_upscale = 3\n",
    "img_blur = img_upscale\n",
    "threshold = 150\n",
    "\n",
    "to_find = \"me\"\n",
    "\n",
    "loc = 'input/it-ends-with-us-split.pdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_pass(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(path):\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pages(pages, root_name):\n",
    "    path = \"temp/page_images/\" + root_name\n",
    "    dir_pass(path)\n",
    "    for index, page in enumerate(pages):\n",
    "        cv.imwrite(path+\"/temp_\"+str(index)+\".png\", page)\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(path):\n",
    "    pages = convert_from_path(path, 300)\n",
    "    pages_cv = [page.convert('L') for page in pages]\n",
    "    pages_np = [np.asarray(page) for page in pages_cv]\n",
    "    if save_artefacts:\n",
    "        save_pages(pages_np, get_filename(path))\n",
    "    return pages_cv, pages_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(page):\n",
    "    data = pytesseract.image_to_boxes(page).strip().split(\"\\n\")\n",
    "    data = [k.split(\" \")[1:-1] for k in data]\n",
    "    data = [[int(t) for t in k] for k in data]\n",
    "\n",
    "    text = pytesseract.image_to_string(page).strip().replace(\"\\n\", \" \")\n",
    "\n",
    "    return data, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data, text):\n",
    "    mapped_input = []\n",
    "    ind_data = 0\n",
    "    for letter in text:\n",
    "        if letter != \" \":\n",
    "            mapped_input += [letter, data[ind_data]],\n",
    "            ind_data += 1\n",
    "            continue\n",
    "        mapped_input += [letter, [0, 0, 0, 0]],\n",
    "\n",
    "    return mapped_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(data, height):\n",
    "    new_data = []\n",
    "    for datum in data:\n",
    "        new_data += [datum[0], [datum[1][0], height -\n",
    "                                datum[1][3], datum[1][2], height - datum[1][1]]],\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_boundary(data):\n",
    "    if not len(data):\n",
    "        return None, None\n",
    "    word = \"\".join([k[0] for k in data])\n",
    "    boundaries = np.array([k[1] for k in data]).T\n",
    "    temp_bound = [min(boundaries[0])-10, min(boundaries[1])-10,\n",
    "                  max(boundaries[2])+10, max(boundaries[3])+10]\n",
    "    return word.lower(), temp_bound\n",
    "\n",
    "\n",
    "def merge_words(data):\n",
    "    new_data = {}\n",
    "    temp = []\n",
    "    for dat in data:\n",
    "        if dat[0] == \" \":\n",
    "            word, boundary = get_word_boundary(temp)\n",
    "            if word:\n",
    "                if word not in new_data:\n",
    "                    new_data[word] = []\n",
    "                new_data[word] += boundary,\n",
    "            temp = []\n",
    "            continue\n",
    "        if dat[0] in [\".\", \",\", \"“\", \"”\"]:\n",
    "            continue\n",
    "        temp += dat,\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(page_cv, page_np):\n",
    "    raw_data = get_all_data(page_cv)\n",
    "    full_split_data = normalize_data(*raw_data)\n",
    "    normalized = normalize_coordinates(full_split_data, page_np.shape[0])\n",
    "    merged = merge_words(normalized)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_instances_as_img(merged, word, img):\n",
    "    stack = []\n",
    "    if word not in merged:\n",
    "        return stack\n",
    "    for box in merged[word]:\n",
    "        base = np.copy(img[box[1]-padding_out:box[3] +\n",
    "                           padding_out, box[0]-padding_out:box[2]+padding_out])\n",
    "        base = np.kron(base, np.ones((img_upscale, img_upscale)))\n",
    "        base = gaussian_filter(base, sigma=img_blur)\n",
    "\n",
    "        current = np.copy(base[padding_out*img_upscale:-padding_out *\n",
    "                               img_upscale, padding_out*img_upscale:-padding_out*img_upscale])\n",
    "        current[current <= threshold] = 0\n",
    "        current[current > threshold] = 255\n",
    "\n",
    "        base[padding_out*img_upscale:-padding_out * img_upscale,\n",
    "             padding_out*img_upscale:-padding_out*img_upscale] = current\n",
    "\n",
    "        stack += base,\n",
    "    return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_instances_to_disk(arr, name, page):\n",
    "    root = \"temp/word_images/\"+name+\"/\"\n",
    "    dir_pass(root)\n",
    "    for index, k in enumerate(arr):\n",
    "        cv.imwrite(f\"{root}{page:03}_{index:03}.png\", k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_word_images(page_cv, page_np):\n",
    "    merged = process_page(page_cv, page_np)\n",
    "    temp = get_all_instances_as_img(merged, to_find, page_np)\n",
    "    if not len(temp):\n",
    "        return []\n",
    "\n",
    "    shapes = np.array([k.shape for k in temp])\n",
    "    x, y = np.min(shapes, axis=0)\n",
    "    x -= x % 2\n",
    "    y -= y % 2\n",
    "\n",
    "    final_planes = []\n",
    "\n",
    "    for instance in temp:\n",
    "        X, Y = instance.shape\n",
    "        dx = int((X-x)/2)\n",
    "        dy = int((Y-y)/2)\n",
    "        final_planes += instance[dx:-dx-1, dy:-dy-1][:x-1, :y-1],\n",
    "    return final_planes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pass(\"temp\")\n",
    "dir_pass(\"outs/\"+to_find)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pages_cv, pages_np = get_pages(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for page_no, (page_cv, page_np) in enumerate(zip(pages_cv, pages_np)):\n",
    "    final_word_images = get_final_word_images(page_cv, page_np)\n",
    "    all_words += final_word_images\n",
    "    write_all_instances_to_disk(\n",
    "        final_word_images, get_filename(loc)+\"/\"+to_find, page_no)\n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg -framerate 10 -pattern_type glob -i '\n",
    "# /word_images/it-ends-with-us-split/*.png' -c:v libx264 out.mp4\n",
    "framerate = 10\n",
    "in_ = \"temp/word_images/\"+get_filename(loc)+\"/\"+to_find+\"/*.png\"\n",
    "out_ = \"outs/\"+get_filename(loc)+\"/\"+to_find+\".mp4\"\n",
    "dir_pass(out_.rsplit(\"/\", 1)[0])\n",
    "\n",
    "command = f\"ffmpeg -framerate {framerate} -pattern_type glob -i '{in_}' -c:v libx264 {out_}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7e13742b2c6e5184591a931570eca4b3a24e383ce600d55cbe44df10492fab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
